{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14c614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02fd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8792\\1884070253.py:4: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv('train_dt/movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "#load training dataset\n",
    "ratings = pd.read_csv('train_dt/ratings_small.csv')\n",
    "\n",
    "movies_metadata = pd.read_csv('train_dt/movies_metadata.csv')\n",
    "\n",
    "credits = pd.read_csv('train_dt/credits.csv')\n",
    "\n",
    "keywords = pd.read_csv('train_dt/keywords.csv')\n",
    "\n",
    "links = pd.read_csv('train_dt/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09283cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ur4592644</td>\n",
       "      <td>tt0120884</td>\n",
       "      <td>10</td>\n",
       "      <td>16 January 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ur3174947</td>\n",
       "      <td>tt0118688</td>\n",
       "      <td>3</td>\n",
       "      <td>16 January 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ur3780035</td>\n",
       "      <td>tt0387887</td>\n",
       "      <td>8</td>\n",
       "      <td>16 January 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ur4592628</td>\n",
       "      <td>tt0346491</td>\n",
       "      <td>1</td>\n",
       "      <td>16 January 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ur3174947</td>\n",
       "      <td>tt0094721</td>\n",
       "      <td>8</td>\n",
       "      <td>16 January 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id    imdb_id rating      rating_date\n",
       "0  ur4592644  tt0120884     10  16 January 2005\n",
       "1  ur3174947  tt0118688      3  16 January 2005\n",
       "2  ur3780035  tt0387887      8  16 January 2005\n",
       "3  ur4592628  tt0346491      1  16 January 2005\n",
       "4  ur3174947  tt0094721      8  16 January 2005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load test dataset\n",
    "test_dt = np.load('test_dt/Dataset.npy')\n",
    "test_dt = pd.DataFrame(test_dt)\n",
    "\n",
    "test_dt = test_dt[0].str.split(\",\", expand=True).rename(columns={0:'user_id', 1:\"imdb_id\", 2:\"rating\", 3:'rating_date'})\n",
    "test_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd248ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(test_dt['user_id'].value_counts())\n",
    "row_list = list(temp.index.values)\n",
    "temp.reset_index(inplace = True)\n",
    "temp.columns = ['user_id','rating_cnt']\n",
    "temp = temp.drop(temp[temp['rating_cnt'] < 5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdccc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = list(temp['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e22e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814c064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_list in 'ur4592644'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2cf19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1           True\n",
       "2           True\n",
       "3          False\n",
       "4           True\n",
       "           ...  \n",
       "4669815     True\n",
       "4669816     True\n",
       "4669817    False\n",
       "4669818     True\n",
       "4669819     True\n",
       "Name: user_id, Length: 4669820, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dt['user_id'].isin(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb006815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#movies metadata preprocessing\n",
    "movies_metadata.dropna(inplace = True)\n",
    "\n",
    "#'id'형식이 날짜 형식인 경우 -> 잘못된 경우\n",
    "#ex) ValueError: Unable to parse string \"2012-09-29\" at position 29502\n",
    "movies_metadata['isIdRight'] = movies_metadata['id'].str.contains('|'.join('-'))\n",
    "movies_metadata = movies_metadata[movies_metadata['isIdRight'] == False]\n",
    "movies_metadata.drop(['isIdRight'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendation(keywords, credits, movies_metadata):\n",
    "    keywords['id'] = keywords['id'].astype('int')\n",
    "    credits['id'] = credits['id'].astype('int')\n",
    "    movies_metadata['id'] = movies_metadata['id'].astype('int')\n",
    "    \n",
    "    #content based dataset\n",
    "    cb_trained_dt = movies_metadata\n",
    "    cb_trained_dt = cb_trained_dt.merge(credits, on='id')\n",
    "    cb_trained_dt = cb_trained_dt.merge(keywords, on='id')\n",
    "    \n",
    "    from ast import literal_eval\n",
    "    #Parse the stringified features into their corresponding python objects\n",
    "    features = ['cast', 'crew', 'keywords', 'genres']\n",
    "    for feature in features:\n",
    "        cb_trained_dt[feature] = cb_trained_dt[feature].apply(literal_eval)\n",
    "        \n",
    "    #apply func : 괄호 안의 함수를 dataframe 전체에 적용\n",
    "    #related link : https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=wideeyed&logNo=221559041280\n",
    "    cb_trained_dt['director'] = cb_trained_dt['crew'].apply(get_director)\n",
    "\n",
    "    features = ['cast', 'keywords', 'genres']\n",
    "    for feature in features:\n",
    "        cb_trained_dt[feature] = cb_trained_dt[feature].apply(get_list)\n",
    "\n",
    "    features = ['cast', 'keywords', 'director', 'genres']\n",
    "    for feature in features:\n",
    "        cb_trained_dt[feature] = cb_trained_dt[feature].apply(clean_data)\n",
    "        \n",
    "    #soup라는 column에 keyword, cast, director, genres를 모두 묶어 cosine similarity를 측정할 수 있는 값들을 합쳐서 넣어둠\n",
    "    cb_trained_dt['soup'] = cb_trained_dt.apply(create_soup, axis=1)\n",
    "    \n",
    "    return make_recommendation_user_input(cb_trained_dt)\n",
    "#영화 관련자 중 배우만 따로 빼서(parsing해서) 보관하는 함수\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "#id 등으로 복잡하게 되어 있는 경우 이를 parsing해서 list로 return해주는 함수\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #if len(names) > 3: --> 3개 이상인 경우는 names에서 제거 : 없애고 실행함 (정확도 상승?)\n",
    "            #names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []\n",
    "#빈칸 제거 함수\n",
    "def clean_data(x):\n",
    "    #list 내부의 빈칸 제거 -> [cast, keywords, genres]\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x] #str.lower(대문자 -> 소문자 변경) + 빈칸 제거\n",
    "    else:\n",
    "        #string 내부의 빈칸 제거 -> [director]\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))#빈칸 제거\n",
    "        else:\n",
    "            return ''\n",
    "#cosine similarity function을 위한 말뭉치 생성\n",
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "#get input and return output\n",
    "def get_searchTerms():\n",
    "    searchTerms = [] \n",
    "    genres = input(\"What Movie Genre(if multiple, please separate them with a comma)? [Type 'skip' to skip] \")\n",
    "    genres = \" \".join([\"\".join(n.split()) for n in genres.lower().split(',')])\n",
    "    if genres != 'skip':\n",
    "        searchTerms.append(genres)\n",
    "\n",
    "    actors = input(\"Who are some actors(within the genre)(if multiple, please separate them with a comma)? [Type 'skip' to skip] \")\n",
    "    actors = \" \".join([\"\".join(n.split()) for n in actors.lower().split(',')])\n",
    "    if actors != 'skip':\n",
    "        searchTerms.append(actors)\n",
    "\n",
    "    directors = input(\"Who are some directors(within the genre)(if multiple, please separate them with a comma)? [Type 'skip' to skip] \")\n",
    "    directors = \" \".join([\"\".join(n.split()) for n in directors.lower().split(',')])\n",
    "    if directors != 'skip':\n",
    "        searchTerms.append(directors)\n",
    "\n",
    "    keywords = input(\"What are some of the keywords(ex, friendship)? (if multiple, please separate them with a comma)? [Type 'skip' to skip] \")\n",
    "    keywords = \" \".join([\"\".join(n.split()) for n in keywords.lower().split(',')])\n",
    "    if keywords != 'skip':\n",
    "        searchTerms.append(keywords)\n",
    "\n",
    "    return searchTerms\n",
    "def make_recommendation_user_input(metadata=cb_trained_dt):\n",
    "    new_row = metadata.iloc[-1,:].copy() #creating a copy of the last row of the \n",
    "  #dataset, which we will use to input the user's input\n",
    "  \n",
    "  #grabbing the new wordsoup from the user\n",
    "    searchTerms = get_searchTerms()  \n",
    "    new_row.iloc[-1] = \" \".join(searchTerms) #adding the input to our new row\n",
    "  \n",
    "  #adding the new row to the dataset\n",
    "    metadata = metadata.append(new_row)\n",
    "  \n",
    "  #Vectorizing the entire matrix as described above!\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(metadata['soup'])\n",
    "\n",
    "  #running pairwise cosine similarity \n",
    "    cosine_sim2 = cosine_similarity(count_matrix, count_matrix) #getting a similarity matrix\n",
    "  \n",
    "  #sorting cosine similarities by highest to lowest\n",
    "    sim_scores = list(enumerate(cosine_sim2[-1,:]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "  #matching the similarities to the movie titles and ids\n",
    "    ranked_titles = []\n",
    "    for i in range(1, 5 + 1):\n",
    "        indx = sim_scores[i][0] \n",
    "        ranked_titles.append([metadata['title'].iloc[indx], 'https://imdb.com/title/' + metadata['imdb_id'].iloc[indx]]) #대신 사이트 주소 출력\n",
    "  \n",
    "    return ranked_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc928de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = content_based_recommendation(keywords, credits, movies_metadata)\n",
    "\n",
    "for i in rank_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd01f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
